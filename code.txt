# config/settings.py
class Settings:
    """Класс для хранения настроек приложения."""
    TABLE_FORMAT = "pretty"
    MIN_SEGMENT_DURATION = 5.0

settings = Settings()


# core/db_manager.py
import os
import sqlite3
from datetime import datetime
import hashlib
import logging
from typing import Optional, Dict, List, Tuple
from dataclasses import dataclass

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

@dataclass
class Patient:
    patient_id: int
    name: str
    sex: str
    age: int
    note: str = ""

@dataclass
class EDFFile:
    edf_id: int
    patient_id: int
    file_hash: str
    start_date: float
    eeg_ch: int
    rate: float
    montage: str = ""
    notes: str = ""

@dataclass
class Segment:
    seg_id: int
    patient_id: int
    edf_id: int
    seg_fpath: str
    start_time: float
    end_time: float
    l_marker: str
    r_marker: str
    notes: str = ""

@dataclass
class Diagnosis:
    patient_id: int
    ds_code: str
    ds_descript: str
    note: str = ""

class DBManager:
    def __init__(self, directory: str = ""):
        """Инициализация менеджера БД с хранением всех файлов в подпапке DB."""
        self.directory = os.path.join(directory, "DB") if directory else "DB"
        os.makedirs(self.directory, exist_ok=True)  # Создаем папку если не существует
        self.db_path = os.path.join(self.directory, "eeg_database.db")
        self.segments_dir = os.path.join(self.directory, "segments")
        os.makedirs(self.segments_dir, exist_ok=True)
        self.conn = None
        self._initialize_db()

    def _initialize_db(self):
        """Initialize database connection and create tables if they don't exist."""
        db_dir = os.path.dirname(self.db_path)
        if not os.path.exists(db_dir):
            os.makedirs(db_dir)
            logging.info(f"Created database directory: {db_dir}")

        self.conn = sqlite3.connect(self.db_path)
        self._create_tables()

    def _create_tables(self):
        """Create database tables if they don't exist."""
        cursor = self.conn.cursor()

        cursor.execute("""
        CREATE TABLE IF NOT EXISTS patients (
            patient_id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT NOT NULL,
            sex TEXT CHECK(sex IN ('M', 'F', 'N')) DEFAULT 'N',
            age INTEGER,
            note TEXT DEFAULT ''
        )
        """)

        # EDF files table
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS edf_files (
            edf_id INTEGER PRIMARY KEY AUTOINCREMENT,
            patient_id INTEGER NOT NULL,
            file_hash TEXT UNIQUE NOT NULL,
            start_date REAL NOT NULL,
            eeg_ch INTEGER NOT NULL,
            rate REAL NOT NULL,
            montage TEXT DEFAULT '',
            notes TEXT DEFAULT '',
            FOREIGN KEY (patient_id) REFERENCES patients (patient_id)
        )
        """)

        # Segments table
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS segments (
            seg_id INTEGER PRIMARY KEY AUTOINCREMENT,
            patient_id INTEGER NOT NULL,
            edf_id INTEGER NOT NULL,
            seg_fpath TEXT UNIQUE NOT NULL,
            start_time REAL NOT NULL,
            end_time REAL NOT NULL,
            l_marker TEXT NOT NULL,
            r_marker TEXT NOT NULL,
            notes TEXT DEFAULT '',
            FOREIGN KEY (patient_id) REFERENCES patients (patient_id),
            FOREIGN KEY (edf_id) REFERENCES edf_files (edf_id)
        )
        """)

        # Diagnosis table
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS diagnosis (
            patient_id INTEGER NOT NULL,
            ds_code TEXT NOT NULL,
            ds_descript TEXT NOT NULL,
            note TEXT DEFAULT '',
            PRIMARY KEY (patient_id, ds_code),
            FOREIGN KEY (patient_id) REFERENCES patients (patient_id)
        )
        """)
        self.conn.commit()

    def get_last_record(self, table_name: str):
        """Получить последнюю запись из указанной таблицы."""
        cursor = self.conn.cursor()
        cursor.execute(f"SELECT * FROM {table_name} ORDER BY ROWID DESC LIMIT 1")
        return cursor.fetchone()

    def database_size(self) -> int:
        """Получить размер базы данных в байтах."""
        return os.path.getsize(self.db_path)

    def get_table_data(self, table_name: str) -> List[Tuple]:
        """Получить все данные из указанной таблицы."""
        cursor = self.conn.cursor()
        cursor.execute(f"SELECT * FROM {table_name}")
        return cursor.fetchall()

    def get_table_columns(self, table_name: str) -> List[str]:
        """Получить названия колонок таблицы."""
        cursor = self.conn.cursor()
        cursor.execute(f"PRAGMA table_info({table_name})")
        return [column[1] for column in cursor.fetchall()]

    def database_exists(self) -> bool:
        """Check if database file exists."""
        return os.path.exists(self.db_path)

    def add_patient(self, name: str, sex: str, age: int, note: str = "") -> int:
        """Add a new patient to the database or return existing patient_id if patient already exists."""
        # Check if patient already exists
        cursor = self.conn.cursor()
        cursor.execute("SELECT patient_id FROM patients WHERE name = ?", (name,))
        result = cursor.fetchone()
        if result:
            return result[0]
        cursor.execute(
            "INSERT INTO patients (name, sex, age, note) VALUES (?, ?, ?, ?)",
            (name, sex, age, note)
        )
        self.conn.commit()
        return cursor.lastrowid

    def get_table_data_for_export(self, table_name):
        """Получить данные таблицы в виде списка списков."""
        cursor = self.conn.cursor()
        cursor.execute(f"SELECT * FROM {table_name}")
        return cursor.fetchall()

    def add_edf_file(self, patient_id: int, file_hash: str, start_date: float,
                     eeg_ch: int, rate: float, montage: str = "", notes: str = "") -> int:
        """Add a new EDF file to the database."""
        cursor = self.conn.cursor()
        cursor.execute("SELECT edf_id FROM edf_files WHERE file_hash = ?", (file_hash,))
        result = cursor.fetchone()
        if result:
            raise ValueError(f"EDF file with hash {file_hash} already exists in database (edf_id: {result[0]})")
        cursor.execute(
            "INSERT INTO edf_files (patient_id, file_hash, start_date, eeg_ch, rate, montage, notes) "
            "VALUES (?, ?, ?, ?, ?, ?, ?)",
            (patient_id, file_hash, start_date, eeg_ch, rate, montage, notes)
        )
        self.conn.commit()
        return cursor.lastrowid

    def add_segment(self, patient_id: int, edf_id: int, seg_fpath: str,
                    start_time: float, end_time: float, l_marker: str,
                    r_marker: str, notes: str = "") -> int:
        """Add a new segment to the database."""
        cursor = self.conn.cursor()
        cursor.execute("SELECT seg_id FROM segments WHERE seg_fpath = ?", (seg_fpath,))
        result = cursor.fetchone()
        if result:
            raise ValueError(f"Segment with path {seg_fpath} already exists in database (seg_id: {result[0]})")
        cursor.execute(
            "INSERT INTO segments (patient_id, edf_id, seg_fpath, start_time, end_time, l_marker, r_marker, notes) "
            "VALUES (?, ?, ?, ?, ?, ?, ?, ?)",
            (patient_id, edf_id, seg_fpath, start_time, end_time, l_marker, r_marker, notes)
        )
        self.conn.commit()
        return cursor.lastrowid

    def add_diagnosis(self, patient_id: int, ds_code: str, ds_descript: str, note: str = ""):
        """Add a diagnosis for a patient."""
        cursor = self.conn.cursor()
        cursor.execute(
            "INSERT INTO diagnosis (patient_id, ds_code, ds_descript, note) VALUES (?, ?, ?, ?)",
            (patient_id, ds_code, ds_descript, note)
        )
        self.conn.commit()

    def get_patient_by_name(self, name: str) -> Optional[Patient]:
        """Get patient by name."""
        cursor = self.conn.cursor()
        cursor.execute("SELECT * FROM patients WHERE name = ?", (name,))
        row = cursor.fetchone()
        return Patient(*row) if row else None

    def get_edf_file_by_hash(self, file_hash: str) -> Optional[EDFFile]:
        """Get EDF file by its hash."""
        cursor = self.conn.cursor()
        cursor.execute("SELECT * FROM edf_files WHERE file_hash = ?", (file_hash,))
        row = cursor.fetchone()
        return EDFFile(*row) if row else None

    def get_segments_by_edf(self, edf_id: int) -> List[Segment]:
        """Get all segments for a specific EDF file."""
        cursor = self.conn.cursor()
        cursor.execute("SELECT * FROM segments WHERE edf_id = ?", (edf_id,))
        return [Segment(*row) for row in cursor.fetchall()]

    def get_patient_diagnoses(self, patient_id: int) -> List[Diagnosis]:
        """Get all diagnoses for a specific patient."""
        cursor = self.conn.cursor()
        cursor.execute("SELECT * FROM diagnosis WHERE patient_id = ?", (patient_id,))
        return [Diagnosis(*row) for row in cursor.fetchall()]

    def get_database_stats(self) -> Dict[str, int]:
        """Get statistics about database records."""
        cursor = self.conn.cursor()
        stats = {}
        cursor.execute("SELECT COUNT(*) FROM patients")
        stats['patients'] = cursor.fetchone()[0]
        cursor.execute("SELECT COUNT(*) FROM edf_files")
        stats['edf_files'] = cursor.fetchone()[0]
        cursor.execute("SELECT COUNT(*) FROM segments")
        stats['segments'] = cursor.fetchone()[0]
        cursor.execute("SELECT COUNT(*) FROM diagnosis")
        stats['diagnoses'] = cursor.fetchone()[0]
        return stats

    def fill_segments_from_dict(self, seg_dict: Dict, edf_file_path: str) -> Tuple[int, int]:
        """ Fill database with segments from the segment dictionary. """
        file_hash = self._calculate_file_hash(edf_file_path)
        if self.get_edf_file_by_hash(file_hash):
            raise ValueError("EDF file already exists in database")
        first_seg = next(iter(seg_dict.values()))
        raw = first_seg['data'].info
        subject_info = raw.get('subject_info', {})
        name = " ".join([
            subject_info.get('first_name', ''),
            subject_info.get('middle_name', ''),
            subject_info.get('last_name', '')
        ]).strip()
        sex = subject_info.get('sex', 'N')
        if sex == 1:
            sex = 'M'
        elif sex == 2:
            sex = 'F'
        else:
            sex = 'N'
        birthdate = subject_info.get('birthday')
        recording_date = raw.get('meas_date')
        age = None
        if birthdate and recording_date:
            if isinstance(birthdate, str):
                birthdate = datetime.strptime(birthdate, '%Y-%m-%d')
            age = recording_date.year - birthdate.year
            if (recording_date.month, recording_date.day) < (birthdate.month, birthdate.day):
                age -= 1
        patient_id = self.add_patient(name, sex, age)
        start_date = raw.get('meas_date', datetime.now()).timestamp()
        eeg_ch = len([ch for ch in raw['ch_names'] if 'EEG' in ch])
        rate = raw['sfreq']
        edf_id = self.add_edf_file(
            patient_id=patient_id,
            file_hash=file_hash,
            start_date=start_date,
            eeg_ch=eeg_ch,
            rate=rate
        )
        base_dir = os.path.join(
	        self.segments_dir,
	        os.path.splitext(os.path.basename(edf_file_path))[0]
        )
        os.makedirs(base_dir, exist_ok=True)
        for seg_name, seg_data in seg_dict.items():
            clean_seg_name = "".join(c if c.isalnum() else "_" for c in seg_name)
            seg_fname = f"seg_{clean_seg_name}_eeg.fif"
            seg_fpath = os.path.join(base_dir, seg_fname)
            seg_data['data'].save(seg_fpath, overwrite=True)
            self.add_segment(
                patient_id=patient_id,
                edf_id=edf_id,
                seg_fpath=seg_fpath,
                start_time=seg_data['start_time'],
                end_time=seg_data['end_time'],
                l_marker=seg_data['current_event'],
                r_marker=seg_data['next_event']
            )
        return patient_id, edf_id

    @staticmethod
    def _calculate_file_hash(file_path: str, algorithm: str = "sha256") -> str:
        """Calculate hash of a file."""
        hash_func = hashlib.new(algorithm)
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_func.update(chunk)
        return hash_func.hexdigest()

    def close(self):
        """Close database connection."""
        if self.conn:
            self.conn.close()
            self.conn = None

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()


# core/edf_processor.py
import os
import hashlib
import random
import csv
from collections import defaultdict
from datetime import timedelta
from dateutil.parser import parse
from tqdm import tqdm
from mne.io import read_raw_edf
from mne import find_events
from pandas import DataFrame
import logging
from transliterate import translit
from core.edf_visualizer import EDFVisualizer
from concurrent.futures import ThreadPoolExecutor, as_completed

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

class EDFProcessor:
    def __init__(self, directory):
        self.directory = directory
        self.output_dir = os.path.join(self.directory, "output")
        os.makedirs(self.output_dir, exist_ok=True)
        self.visualizer = EDFVisualizer(self.output_dir)

    def check_directory(self):
        """Check if the directory exists."""
        if not os.path.exists(self.directory):
            raise FileNotFoundError(f"Directory {self.directory} does not exist.")
        return True

    @staticmethod
    def get_edf_metadata(file_path, detailed=False):
        """ Extract metadata from an EDF file. """
        try:
            raw = read_raw_edf(file_path, preload=False)
            info = raw.info
            subject_info = info.get('subject_info', {})
            metadata = {
                'file_name': os.path.basename(file_path),
                'subject_info': subject_info,
                'duration': raw.times[-1],
                'channels': info['ch_names'],
                'sfreq': info['sfreq'],
                'meas_date': info.get('meas_date', None)
            }
            if detailed:
                metadata['events'] = find_events(raw) if 'stim' in info['ch_names'] else None

            return metadata
        except Exception as e:
            logging.error(f"Error reading file {file_path}: {e}")
            return None

    @staticmethod
    def format_filename(filename):
        """Format the filename: remove extra underscores and capitalize first and middle names."""
        filename = filename.strip('_')
        parts = filename.split('_')
        formatted_parts = [part.capitalize() if part.isalpha() else part for part in parts]
        return '_'.join(formatted_parts)

    def rename_edf_files(self):
        """Rename EDF files in the directory."""
        edf_files = [f for f in os.listdir(self.directory) if f.endswith('.edf')]
        renamed_count = 0

        with ThreadPoolExecutor() as executor:
            futures = {executor.submit(self.get_edf_metadata, os.path.join(self.directory, file)): file for file in
                       edf_files}
            for future in tqdm(as_completed(futures), total=len(futures), desc="Renaming files", unit="file"):
                file = futures[future]
                try:
                    metadata = future.result()
                    if metadata:
                        subject_info = metadata['subject_info']
                        first_name = subject_info.get('first_name', '').strip().capitalize()
                        middle_name = subject_info.get('middle_name', '').strip().capitalize()
                        last_name = subject_info.get('last_name', '').strip().capitalize()
                        patient_name = f"{first_name}_{middle_name}_{last_name}".strip()
                        if not patient_name:
                            patient_name = 'Unknown'

                        recording_date = metadata.get('meas_date', 'Unknown_Date')
                        if recording_date:
                            recording_date = recording_date.strftime('%Y-%m-%d_%H-%M-%S')

                        formatted_patient_name = self.format_filename(patient_name)
                        new_name = f"{formatted_patient_name}_{recording_date}.edf"
                        new_file_path = os.path.join(self.directory, new_name)

                        counter = 1
                        while os.path.exists(new_file_path):
                            new_name = f"{formatted_patient_name}_{recording_date}_{counter}.edf"
                            new_file_path = os.path.join(self.directory, new_name)
                            counter += 1

                        os.rename(os.path.join(self.directory, file), new_file_path)
                        renamed_count += 1
                    else:
                        logging.warning(f"Failed to extract metadata for file {file}")
                except Exception as e:
                    logging.error(f"Error renaming file {file}: {e}")

        return renamed_count

    def analyze_directory(self):
        """Analyze all EDF files in the specified directory."""
        metadata_list = []
        files = [os.path.join(self.directory, f) for f in os.listdir(self.directory) if f.endswith('.edf')]

        with ThreadPoolExecutor() as executor:
            futures = [executor.submit(self.get_edf_metadata, file) for file in files]
            for future in tqdm(as_completed(futures), total=len(futures), desc="Analyzing files", unit="file"):
                try:
                    metadata = future.result()
                    if metadata:
                        metadata_list.append(metadata)
                except Exception as e:
                    logging.error(f"Error analyzing file: {e}")

        return metadata_list

    @staticmethod
    def is_edf_corrupted(file_path):
        """Check if an EDF file is corrupted."""
        try:
            raw = read_raw_edf(file_path, verbose=False)
            return False
        except Exception as e:
            logging.error(f"Error reading file {file_path}: {e}")
            return True

    def find_and_delete_corrupted_edf(self):
        """Find and delete corrupted EDF files in the specified folder."""
        deleted_files = 0
        edf_files = [os.path.join(root, file) for root, _, files in os.walk(self.directory) for file in files if
                     file.endswith(".edf")]

        with ThreadPoolExecutor() as executor:
            futures = {executor.submit(self.is_edf_corrupted, file): file for file in edf_files}
            for future in tqdm(as_completed(futures), total=len(futures), desc="Checking files", unit="file"):
                file = futures[future]
                try:
                    if future.result():
                        logging.warning(f"Corrupted file: {file}")
                        os.remove(file)
                        logging.info(f"File deleted: {file}")
                        deleted_files += 1
                except Exception as e:
                    logging.error(f"Error deleting file {file}: {e}")

        return deleted_files

    @staticmethod
    def get_edf_start_time(file_path):
        """Extract the recording start time from an EDF file."""
        try:
            raw = read_raw_edf(file_path, verbose=False)
            start_datetime = raw.info['meas_date']
            if start_datetime:
                return start_datetime
            return None
        except Exception as e:
            logging.error(f"Error reading file {file_path}: {e}")
            return None

    def find_edf_with_similar_start_time(self, time_delta=timedelta(minutes=10)):
        """Find EDF files with similar start times."""
        time_dict = defaultdict(list)
        edf_files = [os.path.join(root, file) for root, _, files in os.walk(self.directory) for file in files if
                     file.lower().endswith('.edf')]

        with ThreadPoolExecutor() as executor:
            futures = {executor.submit(self.get_edf_start_time, file): file for file in edf_files}
            for future in tqdm(as_completed(futures), total=len(futures), desc="Processing files", unit="file"):
                file = futures[future]
                try:
                    start_datetime = future.result()
                    if start_datetime:
                        rounded_time = start_datetime - timedelta(minutes=start_datetime.minute % 10)
                        time_dict[rounded_time].append((start_datetime, file))
                except Exception as e:
                    logging.error(f"Error processing file {file}: {e}")

        similar_time_groups = []
        for rounded_time, files in time_dict.items():
            if len(files) > 1:
                files.sort()
                for i in range(1, len(files)):
                    if files[i][0] - files[i - 1][0] <= time_delta:
                        similar_time_groups.append(files)
                        break

        return similar_time_groups

    @staticmethod
    def calculate_file_hash(file_path, hash_algorithm="md5", chunk_size=8192):
        """Calculate the file hash for content verification."""
        hash_func = hashlib.new(hash_algorithm)
        with open(file_path, "rb") as f:
            while chunk := f.read(chunk_size):
                hash_func.update(chunk)
        return hash_func.hexdigest()

    def find_duplicate_files(self):
        """Find duplicate files in the specified directory."""
        size_dict = defaultdict(list)

        for root, _, files in os.walk(self.directory):
            for file in files:
                file_path = os.path.join(root, file)
                file_size = os.path.getsize(file_path)
                size_dict[file_size].append(file_path)

        hash_dict = defaultdict(list)
        for size, paths in tqdm(size_dict.items(), desc="Checking files", unit="group"):
            if len(paths) > 1:
                for path in paths:
                    file_hash = self.calculate_file_hash(path)
                    hash_dict[file_hash].append(path)

        duplicates = {hash_val: paths for hash_val, paths in hash_dict.items() if len(paths) > 1}
        return duplicates

    @staticmethod
    def delete_duplicates(duplicates):
        """Delete all duplicates except one."""
        for hash_val, paths in duplicates.items():
            for path in tqdm(paths[1:], desc="Deleting duplicates", unit="file"):
                try:
                    os.remove(path)
                    logging.info(f"Deleted file: {path}")
                except OSError as e:
                    logging.error(f"Error deleting file {path}: {e}")

    @staticmethod
    def calculate_age(birthdate, recording_date):
        """Calculate the age at the time of recording."""
        try:
            if isinstance(birthdate, str):
                birthdate = parse(birthdate)
            if isinstance(recording_date, str):
                recording_date = parse(recording_date)
            if hasattr(recording_date, 'tzinfo') and recording_date.tzinfo is not None:
                recording_date = recording_date.replace(tzinfo=None)
            age = recording_date.year - birthdate.year
            if (recording_date.month, recording_date.day) < (birthdate.month, birthdate.day):
                age -= 1
            return age
        except Exception as e:
            logging.error(f"Error calculating age: {e}")
            return None

    def generate_statistics(self, metadata_list):
        """Generate descriptive statistics from metadata and save results."""
        stats = defaultdict(list)
        for metadata in metadata_list:
            subject_info = metadata.get('subject_info', {})
            stats['file_name'].append(metadata['file_name'])
            stats['sex'].append(
                'Male' if subject_info.get('sex') == 1 else 'Female' if subject_info.get('sex') == 2 else 'Unknown')

            birthdate = subject_info.get('birthday')
            recording_date = metadata.get('meas_date')
            if birthdate and recording_date:
                age = self.calculate_age(birthdate, recording_date)
                if age is not None:
                    stats['age'].append(min(age, 60))  # Limit age to 60 years

            stats['duration_minutes'].append(metadata['duration'] / 60)

        df = DataFrame(stats)
        descriptive_stats = {
            'sex_distribution': df['sex'].value_counts(),
            'age_distribution': df['age'].describe() if 'age' in df.columns else None,
            'duration_stats': df['duration_minutes'].describe()
        }
        if self.visualizer is None:
            raise ValueError("Visualizer is not initialized.")
        self.visualizer.visualize_statistics(df)
        output_csv_path = os.path.join(self.output_dir, 'edf_metadata_stats.csv')
        df.to_csv(output_csv_path, index=False)
        with open(os.path.join(self.output_dir, 'descriptive_stats.txt'), 'w') as f:
            f.write("Descriptive Statistics:\n")
            f.write(f"Sex Distribution:\n{descriptive_stats['sex_distribution']}\n")
            f.write(f"Age Distribution:\n{descriptive_stats['age_distribution']}\n")
            f.write(f"Duration Statistics:\n{descriptive_stats['duration_stats']}\n")

        return df, descriptive_stats

    def generate_patient_table(self):
        """Generate a CSV table with unique patient names, sex, and age at recording."""
        files = [f for f in os.listdir(self.directory) if f.endswith(".edf")]
        patient_data = set()

        def process_file(file):
            """Process a single file to extract patient data."""
            try:
                name = self._extract_patient_name(file)
                translated_name = translit(name, 'ru', reversed=True)

                metadata = self.get_edf_metadata(os.path.join(self.directory, file))
                if metadata:
                    subject_info = metadata.get('subject_info', {})

                    sex = subject_info.get('sex', 'Unknown')
                    if sex == 1:
                        sex = 'M'
                    elif sex == 2:
                        sex = 'F'
                    else:
                        sex = 'Unknown'

                    birthdate = subject_info.get('birthday')
                    recording_date = metadata.get('meas_date')
                    age = None
                    if birthdate and recording_date:
                        age = self.calculate_age(birthdate, recording_date)

                    return translated_name, sex, age
            except Exception as e:
                logging.error(f"Error processing file {file}: {e}")
            return None

        with ThreadPoolExecutor() as executor:
            futures = {executor.submit(process_file, file): file for file in files}
            for future in tqdm(as_completed(futures), total=len(futures), desc="Processing files", unit="file"):
                try:
                    result = future.result()
                    if result:
                        patient_data.add(result)
                except Exception as e:
                    logging.error(f"Error processing file: {e}")

        sorted_data = sorted(patient_data, key=lambda x: x[0])

        os.makedirs(self.output_dir, exist_ok=True)
        output_path = os.path.join(self.output_dir, "patient_table.csv")
        with open(output_path, mode='w', newline='', encoding='utf-8') as file:
            writer = csv.writer(file)
            writer.writerow(["Patient Name", "Sex", "Age at Recording (years)"])
            for name, sex, age in sorted_data:
                writer.writerow([name, sex, age if age is not None else "Unknown"])

        return f"Patient table saved to {output_path}"

    @staticmethod
    def _extract_patient_name(filename):
        """Extract patient name from the filename."""
        parts = filename.replace(".edf", "").split("_")
        if len(parts) >= 3:
            return " ".join(parts[:3])
        raise ValueError(f"Invalid file name: {filename}")

    def randomize_filenames(self):
        """Randomize file names in the directory."""
        files = [f for f in os.listdir(self.directory) if os.path.isfile(os.path.join(self.directory, f))]
        used_codes = set()
        name_mapping = []

        for old_name in files:
            new_name = self._generate_unique_code(used_codes) + os.path.splitext(old_name)[1]
            os.rename(os.path.join(self.directory, old_name), os.path.join(self.directory, new_name))
            name_mapping.append((old_name, new_name))

        output_csv_path = os.path.join(self.directory, "name_mapping.csv")
        with open(output_csv_path, mode='w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(['Old Name', 'New Name'])
            writer.writerows(name_mapping)

        return f"File names randomized. Correspondence table saved to {output_csv_path}"

    @staticmethod
    def _generate_unique_code(used_codes):
        """Generate a unique 6-digit numeric code."""
        while True:
            code = ''.join(random.choices('0123456789', k=6))
            if code not in used_codes:
                used_codes.add(code)
                return code

    def remove_patient_info(self):
        """Remove patient information from EDF files."""
        files = [f for f in os.listdir(self.directory) if f.endswith(".edf")]
        for file in tqdm(files, desc="Processing files", unit="file"):
            try:
                self._remove_patient_info(file)
                logging.info(f"Patient information removed from file {file}")
            except Exception as e:
                logging.error(f"Error removing patient information from file {file}: {e}")

    def _remove_patient_info(self, file):
        """Remove patient information from an EDF file, preserving UUID, sex, and birthdate."""
        file_path = os.path.join(self.directory, file)
        try:
            with open(file_path, 'r+b') as f:
                header = f.read(88).decode('ascii')
                parts = header.split()
                if len(parts) >= 5:
                    uuid, sex, birthdate = parts[1], parts[2], parts[3]
                    new_patient_info = f"{uuid} {sex} {birthdate} {'_' * 80}"
                    new_patient_info = new_patient_info[:80]
                    f.seek(8)
                    f.write(new_patient_info.encode('ascii'))
                else:
                    logging.warning(f"Invalid EDF header in file {file}. Cannot remove patient info.")
        except Exception as e:
            logging.error(f"Error processing file {file}: {e}")

    def read_edf_info(self):
        """Read and display information from the first EDF file."""
        files = [f for f in os.listdir(self.directory) if f.endswith(".edf")]
        if not files:
            return "No EDF files found in the directory."

        first_file = files[0]
        try:
            metadata = self.get_edf_metadata(os.path.join(self.directory, first_file), detailed=True)
            if metadata:
                formatted_info = self._format_edf_info(metadata)
                formatted_info += "\nФайл читается и доступен для дальнейшей обработки."
                return formatted_info
            else:
                return "Failed to extract metadata from the file."
        except Exception as e:
            logging.error(f"Error reading information from file {first_file}: {e}")
            return f"Ошибка при чтении файла {first_file}: {e}"

    def _format_edf_info(self, metadata):
        """Format EDF file information for human-readable output."""
        subject_info = metadata.get('subject_info', {})
        formatted_info = (
            f"Информация о файле: {metadata['file_name']}\n"
            f"Имя пациента: {subject_info.get('first_name', 'Не указано')} "
            f"{subject_info.get('middle_name', '')} "
            f"{subject_info.get('last_name', '')}\n"
            f"Пол: {'Мужской' if subject_info.get('sex') == 1 else 'Женский' if subject_info.get('sex') == 2 else 'Не указан'}\n"
            f"Дата рождения: {subject_info.get('birthday', 'Не указана')}\n"
            f"Дата записи: {metadata.get('meas_date', 'Не указана')}\n"
            f"Длительность записи: {metadata['duration'] / 60:.2f} минут\n"
            f"Частота дискретизации: {metadata['sfreq']} Гц\n"
            f"Каналы: {', '.join(metadata['channels'])}\n"
        )
        return formatted_info

    def run(self):
        """Run the EDF processing pipeline."""
        self.check_directory()
        metadata_list = self.analyze_directory()
        df, descriptive_stats = self.generate_statistics(metadata_list)
        self.visualizer.visualize_statistics(df)
        self.export_statistics(df, descriptive_stats)
        logging.info("EDF processing completed.")

if __name__ == "__main__":
    directory = input("Enter the path to the directory containing EDF files: ").strip()
    processor = EDFProcessor(directory)
    processor.run()


# core/edf_segmentor.py
import mne
from mne.viz import plot_montage
from core.montage_manager import MontageManager
from config.settings import settings
import numpy as np
from tabulate import tabulate
import tkinter as tk
import re

class EventProcessor:
    """Handler for generating event names and processing events."""

    @staticmethod
    def _clean_event_name(name):
        """Cleans event name: removes brackets/parentheses, checks excluded names, translates to English."""
        global excluded_names
        cleaned_name = re.sub(r'\[.*?\]|\(.*?\)', '', name).strip()
        excluded_names = ["stimFlash", "Артефакт", "Начало печати", "Окончание печати", "Эпилептиформная активность", '''Комплекс "острая волна - медленная волна"''']
        if cleaned_name in excluded_names or name in excluded_names:
            return None
        if not cleaned_name:
            return name if name else "Unknown"
        translations = {
            "Фоновая запись": "Baseline",
            "Открывание глаз": "EyesOpen",
            "Закрывание глаз": "EyesClosed",
            "Без стимуляции": "Rest",
            "Фотостимуляция": "PhoticStim",
            "После фотостимуляции": "PostPhotic",
            "Встроенный фотостимулятор": "Photic",
            "Встроенный слуховой стимулятор": "Auditory",
            "Остановка стимуляции": "StimOff",
            "Гипервентиляция": "Hypervent",
            "После гипервентиляции": "PostHypervent",
            "Разрыв записи": "Gap",
            "Бодрствование": "Awake"
        }
        for ru_name, en_name in translations.items():
            if ru_name in cleaned_name:
                if "Photic" in en_name or "Auditory" in en_name:
                    freq_match = re.search(r'(\d+)\s*Гц', name)
                    tone_match = re.search(r'Тон\s*(\d+)\s*Гц', name)
                    if tone_match:
                        return f"{en_name}{tone_match.group(1)}Hz"
                    elif freq_match:
                        return f"{en_name}{freq_match.group(1)}Hz"
                return en_name
        return cleaned_name

    @staticmethod
    def get_event_name(evt_code, ev_id):
        """Returns the event name based on its code."""
        name = next((name for name, code in ev_id.items() if code == evt_code), "Unknown")
        return EventProcessor._clean_event_name(name)

    @staticmethod
    def generate_segment_name(base_name, existing_names):
        """Generates a unique name for a segment."""
        if base_name is None:
            base_name = "Unknown"
        seg_name = base_name
        counter = 1
        while seg_name in existing_names:
            seg_name = f"{base_name}_{counter}"
            counter += 1
        return seg_name

class EDFSegmentor:
    """Class for processing EDF files, including loading metadata and splitting into segments."""
    def __init__(self, output_widget):
        self.seg_dict = {}
        self.output_widget = output_widget
        self.raw = None
        self.events = None
        self.event_id = None
        self.current_file_path = None

    def load_metadata(self, file_path):
        """Loads metadata from an EDF file."""
        self.current_file_path = file_path
        try:
            self.output_widget.delete(1.0, tk.END)
            self.raw = mne.io.read_raw_edf(file_path, preload=True)
            if 'ECG  ECG' in self.raw.ch_names:
                self.raw.drop_channels(['ECG  ECG'])
                self.output_widget.insert(tk.END, "ECG channel removed.\n")
            self.events, self.event_id = mne.events_from_annotations(self.raw)
            self.output_widget.insert(tk.END, self._format_output())
        except Exception as e:
            self.output_widget.insert(tk.END, f"Error: Failed to load metadata: {str(e)}\n")
            raise Exception(f"Failed to load metadata: {str(e)}")

    def _format_output(self):
        """Formats output information about the file, channels, and events."""
        subject_info = self.raw.info.get('subject_info', {})
        output_lines = [
            f"Full Name: {subject_info.get('first_name', 'Not specified')} "
            f"{subject_info.get('middle_name', '')} "
            f"{subject_info.get('last_name', '')}\n",
            f"Date of Birth: {subject_info.get('birthday', 'Not specified')}\n",
            f"Sex: { {1: 'Male', 0: 'Female'}.get(subject_info.get('sex'), 'Not specified') }\n",
            f"Study Date: {subject_info.get('meas_date', 'Not specified')}\n",
            f"Number of channels: {len(self.raw.ch_names)}\n",
            f"Sampling frequency: {self.raw.info['sfreq']} Hz\n"
        ]
        montage = MontageManager.create_montage(len(self.raw.ch_names))
        if montage:
            self.raw.set_montage(montage)
            output_lines.append("Montage successfully applied.\n")
            # plot_montage(montage, kind='topomap', show_names=True, sphere='auto', scale=1.2)
        else:
            output_lines.append("Montage not applied: unsuitable number of channels.\n")
        output_lines.append(self._format_channel_info())
        output_lines.append(self._format_event_info())
        return ''.join(output_lines)

    def _format_channel_info(self):
        """Formats channel information into a table."""
        channels_info = self.raw.info['chs']
        data = []
        for channel in channels_info:
            loc = channel['loc']
            loc_x, loc_y, loc_z = ('-', '-', '-') if len(loc) < 3 or np.isnan(loc[:3]).any() else loc[:3]
            data.append([
                channel['ch_name'], channel['logno'], channel['scanno'], channel['cal'],
                channel['range'], channel['unit_mul'], channel['unit'], channel['coord_frame'],
                channel['coil_type'], channel['kind'], loc_x, loc_y, loc_z
            ])
        headers = [
            "Channel Name", "Logical Number", "Scan Number", "Calibration", "Range",
            "Unit Multiplier", "Unit", "Coordinate Frame", "Coil Type", "Channel Type",
            "Loc X", "Loc Y", "Loc Z"
        ]
        return f"\nChannel Information:\n{tabulate(data, headers, tablefmt=settings.TABLE_FORMAT)}\n"

    def _format_event_info(self):
        """Formats event information into a table."""
        if self.events is None:
            return "No events available in annotations.\n"
        table_data = []
        for s_idx in range(len(self.events)):
            time_index = self.events[s_idx, 0]
            event_id_value = self.events[s_idx, 2]
            evt_name = EventProcessor.get_event_name(event_id_value, self.event_id)
            if evt_name is None:
                continue
            time_seconds = time_index / self.raw.info['sfreq']
            table_data.append([f"{time_seconds:.2f}", event_id_value, evt_name])
        headers = ["Time (sec)", "Event ID", "Description"]
        excluded_events_note = excluded_names
        return f"\nNumber of events: {len(self.events)}\nEvent List{excluded_events_note}:\n{tabulate(table_data, headers, tablefmt=settings.TABLE_FORMAT)}\n"

    def process(self):
        """Processes the EDF file, splitting it into segments without missing intervals."""
        self.output_widget.delete(1.0, tk.END)
        if self.raw is None:
            self.output_widget.insert(tk.END, "Error: Please select an EDF file for processing first.\n")
            raise Exception("Please select an EDF file for processing first.")

        self.output_widget.insert(tk.END, "Starting processing...\n")
        if len(self.events) < 1:
            self.output_widget.insert(tk.END, "No events found in the file.\n")
            return
        valid_indices = []
        for i, event in enumerate(self.events):
            evt_code = event[2]
            evt_name = EventProcessor.get_event_name(evt_code, self.event_id)
            if evt_name is not None:
                valid_indices.append(i)
        if not valid_indices:
            self.output_widget.insert(tk.END, "No valid events found after filtering.\n")
            return
        first_event_time = self.events[valid_indices[0], 0] / self.raw.info['sfreq']
        if first_event_time > settings.MIN_SEGMENT_DURATION:
            seg_name = EventProcessor.generate_segment_name("Start", self.seg_dict.keys())
            seg_data = self.raw.copy().crop(tmin=0, tmax=first_event_time)
            self.seg_dict[seg_name] = {
                'start_time': 0,
                'end_time': first_event_time,
                'current_event': "Start",
                'next_event': EventProcessor.get_event_name(self.events[valid_indices[0], 2], self.event_id),
                'data': seg_data
            }
        for i in range(len(valid_indices)):
            current_idx = valid_indices[i]
            next_idx = valid_indices[i + 1] if i + 1 < len(valid_indices) else None
            self.add_seg(current_idx, next_idx)
        self._output_results()

    def add_seg(self, s_idx, e_idx):
        """Adds a segment to the segment dictionary."""
        s_t = self.events[s_idx, 0] / self.raw.info['sfreq']
        e_t = self.events[e_idx, 0] / self.raw.info['sfreq'] if e_idx is not None else self.raw.times[-1]
        if e_t - s_t < settings.MIN_SEGMENT_DURATION:
            return
        evt_code = self.events[s_idx, 2]
        evt_name = EventProcessor.get_event_name(evt_code, self.event_id)
        next_evt = "End" if e_idx is None else EventProcessor.get_event_name(self.events[e_idx, 2], self.event_id)
        seg_name = EventProcessor.generate_segment_name(evt_name, self.seg_dict.keys())
        seg_data = self.raw.copy().crop(tmin=s_t, tmax=e_t)
        self.seg_dict[seg_name] = {
            'start_time': s_t,
            'end_time': e_t,
            'current_event': evt_name,
            'next_event': next_evt,
            'data': seg_data
        }

    def _output_results(self):
        """Outputs the processing results to the text widget."""
        structure_data = [
            ["Key", "Key", "Type", "Example Value"],
            ["*seg_name*", "", "", ""],
            ["", "", "", ""],
            ["", "start_time", "float", "0.60"],
            ["", "end_time", "float", "15.00"],
            ["", "current_event", "str", "Fon"],
            ["", "next_event", "str", "OG"],
            ["", "data", "RawEDF", "RawEDF Object"]
        ]
        self.output_widget.insert(tk.END, "Segment Dictionary Structure:\n")
        self.output_widget.insert(tk.END, tabulate(structure_data, headers="firstrow", tablefmt=settings.TABLE_FORMAT) + "\n\n")
        table_data = []
        valid_segments_count = 0
        for seg_name, t in self.seg_dict.items():
            duration = t['end_time'] - t['start_time']
            if duration >= settings.MIN_SEGMENT_DURATION:
                table_data.append([
                    seg_name,
                    f"{t['start_time']:.3f}",
                    f"{t['end_time']:.3f}",
                    t['current_event'],
                    t['next_event'],
                    f"{duration:.3f}"
                ])
                valid_segments_count += 1
        headers = ["Segment", "Start", "End", "From", "To", "Duration"]
        self.output_widget.insert(tk.END, f"Number of segments with duration >= {settings.MIN_SEGMENT_DURATION} sec: {valid_segments_count}\n")
        self.output_widget.insert(tk.END, "Segment Data:\n")
        self.output_widget.insert(tk.END, tabulate(table_data, headers, tablefmt=settings.TABLE_FORMAT) + "\n")

    @staticmethod
    def get_event_name(evt_code, ev_id):
        """Returns the translated and shortened event name based on its code."""
        name = next((name for name, code in ev_id.items() if code == evt_code), "Unknown")
        return EventProcessor._clean_event_name(name)

    @staticmethod
    def generate_segment_name(base_name, existing_names):
        """Generates a unique short name for a segment."""
        if base_name is None:
            base_name = "Unknown"

        # Create short version (take first 5 letters if long)
        short_name = base_name[:8] if len(base_name) > 8 else base_name

        # Ensure uniqueness
        seg_name = short_name
        counter = 1
        while seg_name in existing_names:
            seg_name = f"{short_name[:5]}_{counter}"
            counter += 1
        return seg_name


# core/edf_visualizer.py
import os
from seaborn import countplot, histplot
import matplotlib.pyplot as plt

class EDFVisualizer:
    def __init__(self, output_dir):
        """ Initialize the visualizer with the output directory. """
        self.output_dir = os.path.normpath(output_dir)
        os.makedirs(self.output_dir, exist_ok=True)

    def visualize_statistics(self, df):
        """ Visualize statistics and save plots to the output directory. """
        self._visualize_sex_distribution(df)
        self._visualize_age_distribution(df)
        self._visualize_duration_distribution(df)

    def _visualize_sex_distribution(self, df):
        """ Visualize and save the sex distribution plot. """
        if 'sex' in df.columns:
            fig = plt.figure(figsize=(8, 6))
            countplot(data=df, x='sex')
            plt.title('Sex Distribution')
            save_path = os.path.normpath(os.path.join(self.output_dir, 'sex_distribution.png'))
            plt.savefig(save_path)
            plt.close(fig)
            print(f"Сохранено: {save_path}")

    def _visualize_age_distribution(self, df):
        """ Visualize and save the age distribution plot. """
        if 'age' in df.columns:
            age_data = df[df['age'].apply(lambda x: isinstance(x, (int, float)))]
            if not age_data.empty:
                fig = plt.figure(figsize=(8, 6))
                histplot(data=age_data, x='age', bins=20, kde=True)
                plt.title('Age Distribution')
                save_path = os.path.normpath(os.path.join(self.output_dir, 'age_distribution.png'))
                plt.savefig(save_path)
                plt.close(fig)
                print(f"Сохранено: {save_path}")

    def _visualize_duration_distribution(self, df):
        """ Visualize and save the recording duration distribution plot. """
        if 'duration_minutes' in df.columns:
            fig = plt.figure(figsize=(8, 6))
            histplot(data=df, x='duration_minutes', bins=20, kde=True)
            plt.title('Recording Duration (minutes)')
            save_path = os.path.normpath(os.path.join(self.output_dir, 'duration_distribution.png'))
            plt.savefig(save_path)
            plt.close(fig)
            print(f"Сохранено: {save_path}")



# core/montage_manager.py
import mne
import numpy as np

class MontageManager:
    """Class for creating montages (electrode arrangements) for EEG."""
    @staticmethod
    def create_montage(num_channels):
        """Creates a montage based on the number of channels."""
        if num_channels in [10, 11]:
            ch_n = ['EEG F3', 'EEG F4', 'EEG C3', 'EEG C4', 'EEG P3', 'EEG P4', 'EEG O1', 'EEG O2', 'EEG A2', 'EEG A1']
            ch_c = np.array([
                [-0.05, 0.0375, 0.06], [0.05, 0.0375, 0.06],
                [-0.05, 0.0, 0.1], [0.05, 0.0, 0.1],
                [-0.05, -0.0375, 0.08], [0.05, -0.0375, 0.08],
                [-0.05, -0.075, 0.05], [0.05, -0.075, 0.05],
                [0.1, 0.0, -0.002], [-0.1, 0.0, -0.002]
            ])
        elif num_channels in [19, 20]:
            ch_n = [
                'EEG FP1-A1', 'EEG FP2-A2', 'EEG F3-A1', 'EEG F4-A2',
                'EEG C3-A1', 'EEG C4-A2', 'EEG P3-A1', 'EEG P4-A2',
                'EEG O1-A1', 'EEG O2-A2', 'EEG F7-A1', 'EEG F8-A2',
                'EEG T3-A1', 'EEG T4-A2', 'EEG T5-A1', 'EEG T6-A2',
                'EEG FZ-A2', 'EEG CZ-A1', 'EEG PZ-A2'
            ]
            ch_c = np.array([
                [-0.05, 0.075, 0.05], [0.05, 0.075, 0.05],
                [-0.05, 0.0375, 0.06], [0.05, 0.0375, 0.06],
                [-0.05, 0.0, 0.1], [0.05, 0.0, 0.1],
                [-0.05, -0.0375, 0.08], [0.05, -0.0375, 0.08],
                [-0.05, -0.075, 0.05], [0.05, -0.075, 0.05],
                [-0.075, 0.0375, 0.06], [0.075, 0.0375, 0.06],
                [-0.075, 0.0, 0.1], [0.075, 0.0, 0.1],
                [-0.075, -0.0375, 0.08], [0.075, -0.0375, 0.08],
                [0.0, 0.0375, 0.06], [0.0, 0.0, 0.1], [0.0, -0.0375, 0.08]
            ])
        else:
            return None
        dig_pts = [
            dict(ident=i + 1, ch_name=name, r=coord,
                 kind=mne.io.constants.FIFF.FIFFV_POINT_EEG,
                 coord_frame=mne.io.constants.FIFF.FIFFV_COORD_HEAD)
            for i, (name, coord) in enumerate(zip(ch_n, ch_c))
        ]
        return mne.channels.DigMontage(dig=dig_pts, ch_names=ch_n)



# edf_app.py
import tkinter.font as tkfont
import csv
import os
import tkinter as tk
import logging
from tkinter import filedialog, messagebox, scrolledtext, ttk
from config.settings import settings
from core.edf_processor import EDFProcessor
from core.edf_segmentor import EDFSegmentor
from core.db_manager import DBManager
from tabulate import tabulate

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

class EDFApp:
    def __init__(self, root):
        super().__init__()
        self.root = root
        self.root.title("EDF File Manager")
        self.root.geometry("1700x700")
        self.directory = ""
        self.processor = None
        self.segmentor = None
        self.db_manager = None
        self._setup_ui()

    def _try_autoload_db(self):
        """Attempt to automatically load existing database"""
        if not self.directory:
            return
        db_path = os.path.join(self.directory, "DB", "eeg_database.db")
        if os.path.exists(db_path):
            try:
                self.db_manager = DBManager(self.directory)
                self._enable_db_buttons()
                self._update_db_status()
                self.text_output.insert(tk.END, "Automatically loaded existing database\n")
                if hasattr(self, 'segmentor') and self.segmentor and hasattr(self.segmentor, 'current_file_path'):
                    for btn in self.button_frame.winfo_children():
                        if isinstance(btn, tk.Button) and btn["text"] == "Fill":
                            btn.config(state=tk.NORMAL)
            except Exception as e:
                self.text_output.insert(tk.END, f"Error loading database: {str(e)}\n")

    def _setup_ui(self):
        """Initialize the user interface with all buttons in one frame."""
        # Main button frame
        self.button_frame = tk.Frame(self.root)
        self.button_frame.pack(pady=10)
        for i in range(12):
            self.button_frame.grid_columnconfigure(i, weight=1)
        tk.Label(self.button_frame, text="Batch Processing:", font=("Arial", 11)) \
            .grid(row=0, column=0, padx=5, pady=5, sticky="w")
        batch_buttons = [
            ("Open", self.select_directory, "Select folder with EDF files"),
            ("Rename", self.rename_files, "Rename EDF files by metadata"),
            ("Check", self.check_corrupted, "Check for corrupted files"),
            ("Dupes", self.find_duplicates, "Find and delete duplicates"),
            ("Similar", self.find_similar_time, "Find files with similar times"),
            ("EDF Stats", self.generate_stats, "Generate statistics"),
            ("Patients", self.generate_patient_table, "Create patient table"),
            ("Random", self.randomize_filenames, "Randomize filenames"),
            ("Anonym", self.remove_patient_info, "Remove patient info"),
            ("Info", self.read_edf_info, "Show EDF file info"),
        ]
        for idx, (text, command, tooltip) in enumerate(batch_buttons):
            btn = tk.Button(self.button_frame, text=text, width=8, command=command,
                            state=tk.DISABLED if idx > 0 else tk.NORMAL)
            btn.grid(row=0, column=idx + 1, padx=2, pady=5, sticky="ew")
            self._create_tooltip(btn, tooltip)
        tk.Label(self.button_frame, text="Segmentation:", font=("Arial", 11)) \
            .grid(row=1, column=0, padx=5, pady=5, sticky="w")
        seg_buttons = [
            ("Load", self.load_edf_file, "Load EDF file"),
            ("Split", self.split_into_segments, "Split into segments"),
        ]
        for idx, (text, command, tooltip) in enumerate(seg_buttons):
            btn = tk.Button(self.button_frame, text=text, width=8, command=command, state=tk.DISABLED)
            btn.grid(row=1, column=idx + 1, padx=2, pady=5, sticky="ew")
            self._create_tooltip(btn, tooltip)
        tk.Label(self.button_frame, text="Min (sec):", font=("Arial", 9)) \
            .grid(row=1, column=3, padx=2, pady=5, sticky="e")
        self.min_duration_entry = tk.Entry(self.button_frame, width=6)
        self.min_duration_entry.insert(0, str(settings.MIN_SEGMENT_DURATION))
        self.min_duration_entry.grid(row=1, column=4, padx=2, pady=5, sticky="w")
        tk.Button(self.button_frame, text="Set", width=4, command=self.apply_min_duration) \
            .grid(row=1, column=5, padx=2, pady=5, sticky="w")
        tk.Label(self.button_frame, text="Database:", font=("Arial", 11)) \
            .grid(row=2, column=0, padx=5, pady=5, sticky="w")
        db_buttons = [
            ("Create", self.create_database, "Create new database"),
            ("Fill", self.fill_segments, "Fill with segments"),
            ("DB Stats", self.show_db_stats, "Show statistics"),
            ("Edit", self.edit_database, "View/edit tables"),
        ]
        for idx, (text, command, tooltip) in enumerate(db_buttons):
            btn = tk.Button(self.button_frame, text=text, width=8, command=command,
                            state=tk.NORMAL if idx == 0 else tk.DISABLED)
            btn.grid(row=2, column=idx + 1, padx=2, pady=5, sticky="ew")
            self._create_tooltip(btn, tooltip)
        self.db_status_label = tk.Label(self.button_frame, text="[DB Not Created]", fg="red")
        self.db_status_label.grid(row=2, column=6, columnspan=4, padx=5, pady=5, sticky="w")
        tk.Button(self.button_frame, text="Exit", width=8, command=self.root.quit) \
            .grid(row=2, column=10, padx=2, pady=5, sticky="e")
        self.text_output = scrolledtext.ScrolledText(self.root, wrap=tk.WORD, width=210, height=40)
        self.text_output.pack(pady=10)
        self.text_output.bind("<Control-c>", self._copy_text)
        self.text_output.bind("<Control-a>", self._select_all_text)
        self.context_menu = tk.Menu(self.root, tearoff=0)
        self.context_menu.add_command(label="Copy", command=self._copy_text)
        self.text_output.bind("<Button-3>", self._show_context_menu)

        self.btn_batch_process = tk.Button(
            self.button_frame,
            text="All split & Fill",
            command=self.batch_process_edf_files,
            state=tk.DISABLED
        )
        self.btn_batch_process.grid(row=1, column=6, padx=2, pady=5, sticky="ew")
        self._create_tooltip(self.btn_batch_process, "Process all EDF files in folder and save segments to DB")

    def batch_process_edf_files(self):
        """Обработать все EDF файлы в папке и сохранить сегменты в базу данных"""
        if not self.directory:
            messagebox.showwarning("Ошибка", "Сначала выберите рабочую папку")
            return

        if not hasattr(self, 'db_manager') or not self.db_manager:
            messagebox.showwarning("Ошибка", "Сначала создайте базу данных")
            return

        # Получаем список всех EDF файлов в папке
        edf_files = [f for f in os.listdir(self.directory) if f.lower().endswith('.edf')]
        if not edf_files:
            messagebox.showinfo("Информация", "В выбранной папке нет EDF файлов")
            return

        self.text_output.delete(1.0, tk.END)
        self.text_output.insert(tk.END, f"Начинаем пакетную обработку {len(edf_files)} файлов...\n")

        total_segments = 0
        processed_files = 0

        for edf_file in edf_files:
            try:
                file_path = os.path.join(self.directory, edf_file)
                self.text_output.insert(tk.END, f"\nОбработка файла: {edf_file}\n")
                self.text_output.update_idletasks()

                # Создаем сегментатор и загружаем файл
                segmentor = EDFSegmentor(self.text_output)
                segmentor.load_metadata(file_path)
                segmentor.process()

                # Добавляем сегменты в базу данных
                if segmentor.seg_dict:
                    try:
                        patient_id, edf_id = self.db_manager.fill_segments_from_dict(
                            segmentor.seg_dict,
                            file_path
                        )
                        segments_added = len(segmentor.seg_dict)
                        total_segments += segments_added
                        self.text_output.insert(
                            tk.END,
                            f"Добавлено {segments_added} сегментов в БД (Patient ID: {patient_id}, EDF ID: {edf_id})\n"
                        )
                        processed_files += 1
                    except ValueError as e:
                        self.text_output.insert(tk.END, f"Ошибка добавления в БД: {str(e)}\n")
                else:
                    self.text_output.insert(tk.END, "Файл не содержит сегментов для добавления\n")

            except Exception as e:
                self.text_output.insert(tk.END, f"Ошибка обработки файла {edf_file}: {str(e)}\n")
                logging.error(f"Error processing {edf_file}: {e}")
                continue

        # Показываем итоговую статистику
        self.text_output.insert(
            tk.END,
            f"\nПакетная обработка завершена!\n"
            f"Обработано файлов: {processed_files}/{len(edf_files)}\n"
            f"Всего добавлено сегментов: {total_segments}\n"
        )

        # Обновляем статус базы данных
        self._update_db_status()

    def _display_table(self, parent, table_name):
        """Отобразить содержимое таблицы с возможностью сортировки и контекстного меню."""
        for widget in parent.winfo_children():
            if isinstance(widget, tk.Frame) and widget != parent.winfo_children()[0]:
                widget.destroy()
        try:
            table_container = tk.Frame(parent)
            table_container.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
            toolbar = tk.Frame(table_container)
            toolbar.pack(fill=tk.X, pady=(0, 5))
            refresh_btn = tk.Button(toolbar, text="🔄 Обновить",
                                    command=lambda: self._refresh_table(table_container, table_name),
                                    bd=1, relief=tk.RAISED)
            refresh_btn.pack(side=tk.LEFT, padx=2)
            export_btn = tk.Button(toolbar, text="💾 Экспорт в CSV",
                                   command=lambda: self._export_table(table_name),
                                   bd=1, relief=tk.RAISED)
            export_btn.pack(side=tk.LEFT, padx=2)
            columns = self.db_manager.get_table_columns(table_name)
            data = self.db_manager.get_table_data(table_name)
            table_frame = tk.Frame(table_container)
            table_frame.pack(fill=tk.BOTH, expand=True)
            scroll_y = tk.Scrollbar(table_frame)
            scroll_y.pack(side=tk.RIGHT, fill=tk.Y)
            scroll_x = tk.Scrollbar(table_frame, orient=tk.HORIZONTAL)
            scroll_x.pack(side=tk.BOTTOM, fill=tk.X)
            self.tree = ttk.Treeview(table_frame, columns=columns, show="headings",
                                     yscrollcommand=scroll_y.set,
                                     xscrollcommand=scroll_x.set,
                                     selectmode='extended')
            self.tree.pack(fill=tk.BOTH, expand=True)
            scroll_y.config(command=self.tree.yview)
            scroll_x.config(command=self.tree.xview)
            for col in columns:
                self.tree.heading(col, text=col,
                                  command=lambda c=col: self._sort_treeview(self.tree, c, False))
                self.tree.column(col, width=tkfont.Font().measure(col) + 20,
                                 stretch=tk.YES, anchor=tk.W)
            if len(data) > 1000:
                progress = ttk.Progressbar(table_container, orient=tk.HORIZONTAL,
                                           length=200, mode='determinate')
                progress.pack(pady=5)
                progress["maximum"] = len(data)
                batch_size = 100
                for i in range(0, len(data), batch_size):
                    batch = data[i:i + batch_size]
                    for row in batch:
                        self.tree.insert("", tk.END, values=row)
                    progress["value"] = i + len(batch)
                    table_container.update()
                progress.destroy()
            else:
                for row in data:
                    self.tree.insert("", tk.END, values=row)
            self._auto_resize_columns(self.tree, columns)
            self._setup_table_context_menu(table_name)
        except Exception as e:
            messagebox.showerror("Ошибка", f"Не удалось отобразить таблицу {table_name}:\n{str(e)}")

    def _sort_treeview(self, tree, col, reverse):
        """Сортировка Treeview по колонке."""
        data = [(tree.set(child, col), child) for child in tree.get_children('')]
        data.sort(reverse=reverse)
        for index, (val, child) in enumerate(data):
            tree.move(child, '', index)
        tree.heading(col, command=lambda: self._sort_treeview(tree, col, not reverse))

    def _auto_resize_columns(self, tree, columns):
        """Автоматическая подстройка ширины колонок."""
        for col in columns:
            max_width = tkfont.Font().measure(col)
            for row in tree.get_children():
                cell_value = tree.set(row, col)
                max_width = max(max_width, tkfont.Font().measure(str(cell_value)))
            tree.column(col, width=max_width + 20)

    def _setup_table_context_menu(self, table_name):
        """Настройка контекстного меню для таблицы."""
        menu = tk.Menu(self.tree, tearoff=0)
        menu.add_command(label="Копировать", command=self._copy_table_data)
        menu.add_command(label="Редактировать",
                         command=lambda: self._edit_record(table_name))
        menu.add_command(label="Удалить",
                         command=lambda: self._delete_record(table_name))
        self.tree.bind("<Button-3>", lambda event: menu.post(event.x_root, event.y_root))

    def _refresh_table(self, container, table_name):
        """Обновить содержимое таблицы."""
        self._display_table(container, table_name)

    def _export_table(self, table_name):
        """Экспорт таблицы в CSV файл."""
        try:
            file_path = filedialog.asksaveasfilename(
                defaultextension=".csv",
                filetypes=[("CSV Files", "*.csv")],
                title=f"Export {table_name} to CSV"
            )
            if file_path:
                data = self.db_manager.get_table_data(table_name)
                columns = self.db_manager.get_table_columns(table_name)
                with open(file_path, 'w', newline='', encoding='utf-8') as f:
                    writer = csv.writer(f)
                    writer.writerow(columns)
                    writer.writerows(data)
                messagebox.showinfo("Успех", f"Данные экспортированы в:\n{file_path}")
        except Exception as e:
            messagebox.showerror("Ошибка", f"Не удалось экспортировать данные:\n{str(e)}")

    def edit_database(self):
        """Open database editor window."""
        if not self.db_manager:
            messagebox.showwarning("Error", "Database not created. Please create database first.")
            return
        editor = tk.Toplevel(self.root)
        editor.title("Database Editor")
        editor.geometry("1200x600")
        notebook = ttk.Notebook(editor)
        self._create_table_viewer_tab(notebook)
        self._create_sql_editor_tab(notebook)
        notebook.pack(fill="both", expand=True)

    def _load_table_data(self, event):
        """Load selected table data"""
        selection = self.table_listbox.curselection()
        if not selection:
            return
        table_name = self.table_listbox.get(selection[0])
        for widget in self.table_data_frame.winfo_children():
            widget.destroy()
        try:
            columns = self.db_manager.get_table_columns(table_name)
            data = self.db_manager.get_table_data(table_name)
            tree = ttk.Treeview(self.table_data_frame, columns=columns, show="headings")
            for col in columns:
                tree.heading(col, text=col)
                tree.column(col, width=100, anchor=tk.W)
            for row in data:
                tree.insert("", tk.END, values=row)
            scroll_y = ttk.Scrollbar(self.table_data_frame, orient="vertical", command=tree.yview)
            scroll_y.pack(side=tk.RIGHT, fill=tk.Y)
            tree.configure(yscrollcommand=scroll_y.set)
            scroll_x = ttk.Scrollbar(self.table_data_frame, orient="horizontal", command=tree.xview)
            scroll_x.pack(side=tk.BOTTOM, fill=tk.X)
            tree.configure(xscrollcommand=scroll_x.set)
            tree.pack(fill=tk.BOTH, expand=True)
            tk.Label(self.table_data_frame,
                     text=f"Loaded {len(data)} rows from table '{table_name}'",
                     font=('Arial', 8)).pack(side=tk.BOTTOM)
        except Exception as e:
            messagebox.showerror("Error", f"Failed to load table data: {str(e)}")

    def _execute_sql(self):
        """Execute SQL query from editor"""
        query = self.sql_input.get("1.0", tk.END).strip()
        if not query:
            messagebox.showwarning("Warning", "Please enter a SQL query")
            return
        try:
            cursor = self.db_manager.conn.cursor()
            cursor.execute(query)
            for row in self.sql_results.get_children():
                self.sql_results.delete(row)
            self.sql_results["columns"] = []
            if query.lower().strip().startswith(("select", "pragma", "explain")):
                # For SELECT queries - show results in table
                columns = [desc[0] for desc in cursor.description]
                self.sql_results["columns"] = columns
                for col in columns:
                    self.sql_results.heading(col, text=col)
                    self.sql_results.column(col, width=100)
                for row in cursor.fetchall():
                    self.sql_results.insert("", tk.END, values=row)
                messagebox.showinfo("Success", f"Query executed. Returned {len(self.sql_results.get_children())} rows")
            else:
                self.db_manager.conn.commit()
                messagebox.showinfo("Success", f"Query executed. Rows affected: {cursor.rowcount}")
        except Exception as e:
            messagebox.showerror("Error", f"Failed to execute query:\n{str(e)}")

    def _run_quick_query(self, query_template):
        """Run predefined quick query"""
        selection = self.table_listbox.curselection()
        if not selection:
            messagebox.showwarning("Warning", "Please select a table first")
            return

        table_name = self.table_listbox.get(selection[0])
        query = query_template.format(table=table_name)
        self.sql_input.delete("1.0", tk.END)
        self.sql_input.insert("1.0", query)
        if hasattr(self, 'notebook'):
            self.notebook.select(1)  # Switch to SQL tab

    def _clear_sql(self):
        """Clear SQL query editor"""
        self.sql_input.delete("1.0", tk.END)

    def _save_query(self):
        """Save current query to file"""
        query = self.sql_input.get("1.0", tk.END).strip()
        if not query:
            messagebox.showwarning("Warning", "No query to save")
            return
        file_path = filedialog.asksaveasfilename(
            defaultextension=".sql",
            filetypes=[("SQL Files", "*.sql"), ("All Files", "*.*")],
            title="Save SQL Query"
        )
        if file_path:
            try:
                with open(file_path, 'w') as f:
                    f.write(query)
                messagebox.showinfo("Success", "Query saved successfully")
            except Exception as e:
                messagebox.showerror("Error", f"Failed to save query: {str(e)}")

    def _load_query(self):
        """Load SQL query from file"""
        file_path = filedialog.askopenfilename(
            filetypes=[("SQL Files", "*.sql"), ("All Files", "*.*")],
            title="Load SQL Query"
        )
        if file_path:
            try:
                with open(file_path, 'r') as f:
                    query = f.read()
                self.sql_input.delete("1.0", tk.END)
                self.sql_input.insert("1.0", query)
            except Exception as e:
                messagebox.showerror("Error", f"Failed to load query: {str(e)}")

    def _create_table_viewer_tab(self, notebook):
        """Create tab with table selection and viewing"""
        table_frame = ttk.Frame(notebook)
        notebook.add(table_frame, text="Tables")
        list_frame = ttk.Frame(table_frame, width=200)
        list_frame.pack(side=tk.LEFT, fill=tk.Y, padx=5, pady=5)
        tk.Label(list_frame, text="Database Tables", font=('Arial', 10, 'bold')).pack()
        self.table_listbox = tk.Listbox(list_frame)
        self.table_listbox.pack(fill=tk.BOTH, expand=True, pady=5)
        for table in ["patients", "edf_files", "segments", "diagnosis"]:
            self.table_listbox.insert(tk.END, table)
        self.table_listbox.bind('<<ListboxSelect>>', self._load_table_data)
        self.table_data_frame = ttk.Frame(table_frame)
        self.table_data_frame.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True, padx=5, pady=5)

    def _create_sql_editor_tab(self, notebook):
        """Create tab with SQL query editor"""
        sql_frame = ttk.Frame(notebook)
        notebook.add(sql_frame, text="SQL Query")
        tk.Label(sql_frame, text="SQL Query:", font=('Arial', 10, 'bold')).pack(anchor=tk.W)
        self.sql_input = scrolledtext.ScrolledText(sql_frame, wrap=tk.WORD, height=8)
        self.sql_input.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        btn_frame = ttk.Frame(sql_frame)
        btn_frame.pack(fill=tk.X, padx=5, pady=5)
        ttk.Button(btn_frame, text="Execute", command=self._execute_sql).pack(side=tk.LEFT)
        ttk.Button(btn_frame, text="Clear", command=self._clear_sql).pack(side=tk.LEFT)
        ttk.Button(btn_frame, text="Save Query", command=self._save_query).pack(side=tk.RIGHT)
        ttk.Button(btn_frame, text="Load Query", command=self._load_query).pack(side=tk.RIGHT)
        tk.Label(sql_frame, text="Results:", font=('Arial', 10, 'bold')).pack(anchor=tk.W)
        self.sql_results = ttk.Treeview(sql_frame)
        self.sql_results.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        scroll_y = ttk.Scrollbar(sql_frame, orient="vertical", command=self.sql_results.yview)
        scroll_y.pack(side=tk.RIGHT, fill=tk.Y)
        self.sql_results.configure(yscrollcommand=scroll_y.set)
        scroll_x = ttk.Scrollbar(sql_frame, orient="horizontal", command=self.sql_results.xview)
        scroll_x.pack(side=tk.BOTTOM, fill=tk.X)
        self.sql_results.configure(xscrollcommand=scroll_x.set)

    def create_database(self):
        """Создать новую базу данных в папке DB."""
        try:
            if not self.directory:
                messagebox.showwarning("Ошибка", "Сначала выберите рабочую папку")
                return
            db_folder = os.path.join(self.directory, "DB")
            db_path = os.path.join(db_folder, "eeg_database.db")
            os.makedirs(db_folder, exist_ok=True)
            if os.path.exists(db_path):
                if not messagebox.askyesno("Подтверждение",
                                           "База данных уже существует. Пересоздать?"):
                    self.text_output.insert(tk.END, "Используется существующая БД\n")
                    return
            self.db_manager = DBManager(self.directory)
            if not self.db_manager.database_exists():
                raise RuntimeError("Не удалось создать файл БД")
            self.text_output.insert(tk.END, f"База данных создана в:\n{db_path}\n")
            self._enable_db_buttons()
            self._update_db_status()
            if not any(f.lower().endswith('.edf') for f in os.listdir(self.directory)):
                messagebox.showwarning("Предупреждение", "В выбранной папке нет EDF файлов")

        except Exception as e:
            error_msg = f"Error creating database: {str(e)}"
            self.text_output.insert(tk.END, error_msg + "\n")
            messagebox.showerror("Database Error", error_msg)
            if hasattr(self, 'db_manager'):
                del self.db_manager

    def _enable_db_buttons(self):
        """Активировать кнопки работы с базой данных."""
        db_buttons = ["Fill", "Stats", "Edit"]  # Сокращенные названия кнопок из _setup_ui
        for btn in self.button_frame.winfo_children():
            if isinstance(btn, tk.Button) and btn["text"] in db_buttons:
                btn.config(state=tk.NORMAL)

    def _update_db_status(self):
        """Обновить статус базы данных в интерфейсе."""
        if hasattr(self, 'db_manager') and self.db_manager:
            db_name = os.path.basename(self.db_manager.db_path)
            size = os.path.getsize(self.db_manager.db_path) / 1024  # Размер в KB
            self.db_status_label.config(
                text=f"DB: {db_name} ({size:.1f} KB)",
                fg="green",
                font=("Arial", 9, "bold")
            )

    def show_db_stats(self):
        """Показать статистику базы данных с очисткой экрана."""
        self.text_output.delete(1.0, tk.END)  # Очищаем экран
        if not hasattr(self, 'db_manager') or not self.db_manager:
            self.text_output.insert(tk.END, "Database not initialized. Please create database first.\n")
            return
        try:
            stats = self.db_manager.get_database_stats()
            self.text_output.insert(tk.END, "=== DATABASE STATISTICS ===\n")
            self.text_output.insert(tk.END, f"Location: {self.db_manager.db_path}\n\n")
            self.text_output.insert(tk.END, "Records Count:\n")
            self.text_output.insert(tk.END, f"- Patients: {stats['patients']}\n")
            self.text_output.insert(tk.END, f"- EDF Files: {stats['edf_files']}\n")
            self.text_output.insert(tk.END, f"- Segments: {stats['segments']}\n")
            self.text_output.insert(tk.END, f"- Diagnoses: {stats['diagnoses']}\n\n")
            self.text_output.insert(tk.END, "Last Added:\n")
            try:
                last_patient = self.db_manager.get_last_record("patients")
                last_edf = self.db_manager.get_last_record("edf_files")
                self.text_output.insert(tk.END, f"- Last Patient: {last_patient[1]} (ID: {last_patient[0]})\n")
                self.text_output.insert(tk.END, f"- Last EDF File: {last_edf[0]} (Channels: {last_edf[4]})\n")
            except Exception as e:
                self.text_output.insert(tk.END, f"- Additional info unavailable: {str(e)}\n")
        except Exception as e:
            error_msg = f"Error retrieving database stats: {str(e)}"
            self.text_output.insert(tk.END, error_msg + "\n")
            messagebox.showerror("Database Error", error_msg)

    def fill_segments(self):
        """Заполнить базу данных сегментами из текущего словаря."""
        if not self.segmentor or not self.segmentor.seg_dict:
            messagebox.showwarning("Error", "No segments available to add to database.")
            return
        if not self.db_manager:
            messagebox.showwarning("Error", "Database not created. Please create database first.")
            return
        try:
            file_path = getattr(self.segmentor, 'current_file_path', None)
            if not file_path:
                file_path = filedialog.askopenfilename(filetypes=[("EDF files", "*.edf")])
                if not file_path:
                    return
            patient_id, edf_id = self.db_manager.fill_segments_from_dict(
                self.segmentor.seg_dict,
                file_path
            )
            self.text_output.insert(tk.END,
                                    f"Successfully added segments to database. Patient ID: {patient_id}, EDF ID: {edf_id}\n")
            self._show_db_stats()
        except ValueError as e:
            self.text_output.insert(tk.END, f"Error adding segments: {e}\n")
            messagebox.showerror("Error", str(e))
        except Exception as e:
            self.text_output.insert(tk.END, f"Unexpected error: {e}\n")
            messagebox.showerror("Error", f"Failed to add segments: {e}")

    def _show_db_stats(self):
        """Показать статистику базы данных."""
        if not self.db_manager:
            self.text_output.insert(tk.END, "Database not initialized.\n")
            return
        try:
            stats = self.db_manager.get_database_stats()
            self.text_output.insert(tk.END, "Database Statistics:\n")
            self.text_output.insert(tk.END, f"Patients: {stats['patients']}\n")
            self.text_output.insert(tk.END, f"EDF Files: {stats['edf_files']}\n")
            self.text_output.insert(tk.END, f"Segments: {stats['segments']}\n")
            self.text_output.insert(tk.END, f"Diagnoses: {stats['diagnoses']}\n")
        except Exception as e:
            self.text_output.insert(tk.END, f"Error getting database stats: {e}\n")

    def apply_min_duration(self):
        """Apply the minimum segment duration from the entry field."""
        try:
            min_duration = float(self.min_duration_entry.get())
            if min_duration <= 0:
                raise ValueError("Duration must be greater than 0.")
            settings.MIN_SEGMENT_DURATION = min_duration
            messagebox.showinfo("Success", f"Minimum duration set: {min_duration} sec.")
        except ValueError as e:
            messagebox.showerror("Error", str(e))

    def split_into_segments(self):
        """Split the loaded EDF file into segments using the specified minimum duration."""
        if self.segmentor:
            try:
                min_duration = float(self.min_duration_entry.get())
                if min_duration <= 0:
                    raise ValueError("Duration must be greater than 0.")
                settings.MIN_SEGMENT_DURATION = min_duration
                self.segmentor.process()
            except ValueError as e:
                messagebox.showerror("Error", str(e))

    def _copy_text(self, event=None):
        """Copy selected text to clipboard."""
        try:
            selected_text = self.text_output.selection_get()
            self.root.clipboard_clear()
            self.root.clipboard_append(selected_text)
        except tk.TclError:
            pass
        return "break"

    def _select_all_text(self, event=None):
        """Select all text in the output window."""
        self.text_output.tag_add(tk.SEL, "1.0", tk.END)
        self.text_output.mark_set(tk.INSERT, "1.0")
        self.text_output.see(tk.INSERT)
        return "break"

    def _show_context_menu(self, event):
        """Show the context menu on right-click."""
        self.context_menu.post(event.x_root, event.y_root)

    def _create_tooltip(self, widget, text):
        """Create a tooltip for the widget."""
        tooltip = tk.Toplevel(widget)
        tooltip.wm_overrideredirect(True)
        tooltip.wm_geometry("+0+0")
        tooltip.withdraw()
        label = tk.Label(tooltip, text=text, background="#ffffe0", relief="solid", borderwidth=1)
        label.pack()
        widget.bind("<Enter>", lambda e: self._show_tooltip(tooltip, widget))
        widget.bind("<Leave>", lambda e: tooltip.withdraw())

    @staticmethod
    def _show_tooltip(tooltip, widget):
        """Show the tooltip."""
        x, y, _, _ = widget.bbox("insert")
        x += widget.winfo_rootx() + 25
        y += widget.winfo_rooty() + 25
        tooltip.wm_geometry(f"+{x}+{y}")
        tooltip.deiconify()

    def select_directory(self):
        """Select a directory containing EDF files."""
        self.directory = filedialog.askdirectory()
        if self.directory:
            self.text_output.insert(tk.END, f"Selected directory: {self.directory}\n")
            self.processor = EDFProcessor(self.directory)
            for btn in self.button_frame.winfo_children():
                if isinstance(btn, tk.Button) and btn["text"] != "Open":
                    btn.config(state=tk.NORMAL)
            self._try_autoload_db()
            self.btn_batch_process.config(state=tk.NORMAL)

    def load_edf_file(self):
        """Load an EDF file for segmentation."""
        file_path = filedialog.askopenfilename(filetypes=[("EDF files", "*.edf")])
        if file_path:
            self.segmentor = EDFSegmentor(self.text_output)
            self.segmentor.current_file_path = file_path  # Сохраняем путь к файлу
            self.segmentor.load_metadata(file_path)
            for btn in self.button_frame.winfo_children():
                if isinstance(btn, tk.Button) and btn["text"] == "Split into Segments":
                    btn.config(state=tk.NORMAL)
            if self.db_manager:
                for btn in self.button_frame.winfo_children():
                    if isinstance(btn, tk.Button) and btn["text"] == "Fill Segments":
                        btn.config(state=tk.NORMAL)

    def _execute_operation(self, operation_name, operation_func):
        """Execute an operation with error handling."""
        if not self.directory:
            messagebox.showwarning("Error", "Directory not selected.")
            return

        self.text_output.insert(tk.END, f"Started {operation_name}...\n")
        self.text_output.update_idletasks()

        try:
            result = operation_func()
            self.text_output.insert(tk.END, f"{operation_name.capitalize()} completed.\n")
            if result:
                self.text_output.insert(tk.END, f"Result: {result}\n")
        except Exception as e:
            logging.error(f"Error during {operation_name}: {e}")
            self.text_output.insert(tk.END, f"Error: {e}\n")
            messagebox.showerror("Error", f"An error occurred: {e}")

    def rename_files(self):
        """Rename EDF files."""
        self._execute_operation("file renaming process", self.processor.rename_edf_files)

    def find_duplicates(self):
        """Find and delete duplicates."""
        self._execute_operation("duplicate search process", self._find_and_delete_duplicates)

    def check_corrupted(self):
        """Check for corrupted files."""
        self._execute_operation("corrupted file check process", self.processor.find_and_delete_corrupted_edf)

    def generate_stats(self):
        """Generate statistics."""
        self._execute_operation("statistics generation process", self._generate_statistics_wrapper)

    def find_similar_time(self):
        """Find files with similar start times."""
        self._execute_operation("similar time search process", self.processor.find_edf_with_similar_start_time)

    def generate_patient_table(self):
        """Generate patient table."""
        self._execute_operation("patient table creation process", self.processor.generate_patient_table)

    def randomize_filenames(self):
        """Randomize file names."""
        self._execute_operation("filename randomization process", self.processor.randomize_filenames)

    def remove_patient_info(self):
        """Remove patient information."""
        self._execute_operation("patient information removal process", self.processor.remove_patient_info)

    def read_edf_info(self):
        """Read EDF file information."""
        self._execute_operation("EDF file information reading process", self.processor.read_edf_info)

    def _find_and_delete_duplicates(self):
        """Find and delete duplicate files."""
        duplicates = self.processor.find_duplicate_files()
        if duplicates:
            self.text_output.insert(tk.END, "Duplicate files found:\n")
            for hash_val, paths in duplicates.items():
                self.text_output.insert(tk.END, f"Hash: {hash_val}\n")
                for path in paths:
                    self.text_output.insert(tk.END, f"  {path}\n")
            self.processor.delete_duplicates(duplicates)
            return "Duplicates deleted."
        return "No duplicates found."

    def _generate_statistics_wrapper(self):
        """Generate and display statistics."""
        metadata_list = self.processor.analyze_directory()
        df, stats = self.processor.generate_statistics(metadata_list)
        self._display_statistics(stats)
        return "Statistics generated and visualized."

    def _display_statistics(self, stats):
        """Display statistics in the text field."""
        self.text_output.insert(tk.END, "Descriptive statistics:\n")
        if 'sex_distribution' in stats and stats['sex_distribution'] is not None:
            self.text_output.insert(tk.END, "Sex distribution:\n")
            self.text_output.insert(tk.END, tabulate(stats['sex_distribution'].items(), headers=["Sex", "Count"],
                                                     tablefmt="pretty") + "\n")
        if 'age_distribution' in stats and stats['age_distribution'] is not None:
            self.text_output.insert(tk.END, "\nAge distribution:\n")
            age_stats = stats['age_distribution']
            self.text_output.insert(tk.END, tabulate(
                [["Count", int(age_stats['count'])], ["Mean age", f"{age_stats['mean']:.2f} years"],
                 ["Minimum age", f"{age_stats['min']} years"], ["Maximum age", f"{age_stats['max']} years"]],
                headers=["Metric", "Value"], tablefmt="pretty") + "\n")
        if 'duration_stats' in stats and stats['duration_stats'] is not None:
            self.text_output.insert(tk.END, "\nRecording duration statistics (minutes):\n")
            duration_stats = stats['duration_stats']
            self.text_output.insert(tk.END, tabulate([["Mean duration", f"{duration_stats['mean']:.2f} min"],
                                                      ["Minimum duration", f"{duration_stats['min']:.2f} min"],
                                                      ["Maximum duration", f"{duration_stats['max']:.2f} min"]],
                                                     headers=["Metric", "Value"], tablefmt="pretty") + "\n")

if __name__ == "__main__":
    root = tk.Tk()
    app = EDFApp(root)
    root.mainloop()